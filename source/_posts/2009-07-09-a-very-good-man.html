---
layout: post
title: "a very good man"
comments: true
---
<p><sup><a href="http://en.wikipedia.org/wiki/Three_Laws_of_Robotics#cite_note-10"></a></sup></p>  <blockquote>   <p>In his short story &quot;<a href="http://en.wikipedia.org/wiki/Evidence_%28Asimov%29">Evidence</a>&quot;, Asimov lets his recurring character <a href="http://en.wikipedia.org/wiki/Susan_Calvin">Dr. Susan Calvin</a> expound a <a href="http://en.wikipedia.org/wiki/Morality">moral</a> basis behind the Laws. Calvin points out that human beings are typically expected to refrain from harming other human beings (except in times of extreme duress like war, or to save a greater number). This is equivalent to a robot's First Law. Likewise, according to Calvin, society expects individuals to obey instructions from recognized authorities: doctors, teachers and so forth, which equals the Second Law of Robotics. Finally, humans are typically expected to avoid harming themselves, which is the Third Law for a robot. The plot of &quot;Evidence&quot; revolves around the question of telling a human being apart from a robot specially constructed to appear human; Calvin reasons that if such an individual obeys the Laws, he may be a robot or simply &quot;<strong>a very good man</strong>&quot;.</p>    <p>&nbsp;</p>    <p></p>    <p>Another character then asks Calvin if robots are then very different from human beings after all. She replies, <a href="http://oldben.com.ar/post/inhumano.aspx">&quot;Worlds different. Robots are essentially decent.&quot;</a></p> </blockquote>  <p>extract from <a href="http://en.wikipedia.org/wiki/Three_Laws_of_Robotics">Three Laws of Robotics</a> - Wikipedia</p>
